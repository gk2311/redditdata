{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19300c9b",
   "metadata": {},
   "source": [
    "# Introduction to Downloading Data from Reddit\n",
    "\n",
    "Since Tweets download has become slightly difficult and not free. I thought we could atleast explore some social media platform to download user generated content. Let's explore Reddit posts and comments!\n",
    "\n",
    "You can also explore YouTube comments or traditional web scarping!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ad9c4a",
   "metadata": {},
   "source": [
    "# 1: Importing Necessary Libraries\n",
    "\n",
    "In this cell, we'll import the necessary libraries to download the data only. \"praw\" is used to connect with Reddit API and help you download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02e6da45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up Python: Install PRAW\n",
    "# pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fddf340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafd1645",
   "metadata": {},
   "source": [
    "# Downloading data from Reddit\n",
    "\n",
    "Reddit is a great source for user-generated content (UGC). You can use the PRAW library in python to access Reddit data.\n",
    "\n",
    "### Step 1: Apply for a Developer Account\n",
    "1. Go to [Reddit Apps](https://www.reddit.com/prefs/apps).\n",
    "2. Click on \"Create App\" and fill out the form to get your credentials.\n",
    "\n",
    "### Step 2: Create an App\n",
    "When creating an app on Reddit, you need to fill out several fields. For many of these fields, you can use placeholder values if you are not planning to deploy a web app. Here’s how you can fill out the form:\n",
    "\n",
    "1. **Name**: Choose a name for your app. This can be anything that helps you identify the app, like \"MyRedditApp\".\n",
    "\n",
    "2. **App type**: Select \"script\" if you're creating a script to run locally on your machine.\n",
    "\n",
    "3. **Description**: Provide a brief description of what your app does. This is optional but can be helpful for your own records.\n",
    "\n",
    "4. **About URL**: This can be a placeholder URL like http://example.com. It’s not necessary for a script.\n",
    "\n",
    "5. **Redirect URI**: For scripts, you can typically use http://localhost:8080. This is used during the OAuth authentication process.\n",
    "\n",
    "6. **Developer's terms UR**L: This can be a placeholder URL like http://example.com. It’s optional.\n",
    "\n",
    "7. **Save**: Click on the \"Create app\" button.\n",
    "\n",
    "**Note**: Approval might take some time, depending on the details provided.\n",
    "\n",
    "### Step 3: Locating Credentials \n",
    "\n",
    "1. **Client ID**: When you go to the Reddit apps page (Reddit Apps), find your app. The Client ID is a string of characters displayed just below the name of your app. If it’s not obvious, it’s the 14-character string (typically) just below \"personal use script\".\n",
    "\n",
    "2. **Client Secret**: This is labeled as \"secret\" on the app details page. It is a longer string and is shown only once, so copy it and keep it secure.\n",
    "\n",
    "3. **User Agent**: This is a string you create yourself. It should be unique and descriptive. For example, MyRedditApp by /u/YourRedditUsername.\n",
    "\n",
    "### Important Considerations:\n",
    "- Keep your keys and tokens private and secure.\n",
    "- Respect Reddit's Developer Agreement and use the API in accordance with the rules and guidelines.\n",
    "- Monitor your usage to stay within the API rate limits.\n",
    "\n",
    "With your Reddit App set up, you are now ready to explore and analyze Reddit data using various tools and libraries. Happy coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c9a56",
   "metadata": {},
   "source": [
    "# 2: Set Up Reddit API Credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ce089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace these with your own credentials\n",
    "client_id = 'YOUR_CLIENT_ID'  # This is your developer key\n",
    "client_secret = 'YOUR_CLIENT_SECRET'  # This is your secret; while sharing codes, please hide this information\n",
    "user_agent = 'MyRedditApp by /u/YourRedditUsername'  # Create a unique user agent\n",
    "\n",
    "# Authenticate and access Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=client_id,\n",
    "    client_secret=client_secret,\n",
    "    user_agent=user_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd16d8c9",
   "metadata": {},
   "source": [
    "# 3: Fetch Data from Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62911127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created</th>\n",
       "      <th>author</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Billions of crabs went missing around Alaska. ...</td>\n",
       "      <td></td>\n",
       "      <td>4428</td>\n",
       "      <td>17byrco</td>\n",
       "      <td>climatechange</td>\n",
       "      <td>https://www.yahoo.com/news/billions-crabs-went...</td>\n",
       "      <td>738</td>\n",
       "      <td>1.697764e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>[So basically the deep ocean water got warm en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$266 Trillion in Climate Spending Is a No-Brai...</td>\n",
       "      <td></td>\n",
       "      <td>4144</td>\n",
       "      <td>17v43h4</td>\n",
       "      <td>climatechange</td>\n",
       "      <td>https://www.bloomberg.com/opinion/articles/202...</td>\n",
       "      <td>677</td>\n",
       "      <td>1.699974e+09</td>\n",
       "      <td>Splenda</td>\n",
       "      <td>[Back to Math \\n\\nThe earth has 7 billion huma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gray whales have been mysteriously washing up ...</td>\n",
       "      <td></td>\n",
       "      <td>2443</td>\n",
       "      <td>179qtvw</td>\n",
       "      <td>climatechange</td>\n",
       "      <td>https://www.businessinsider.nl/gray-whales-hav...</td>\n",
       "      <td>371</td>\n",
       "      <td>1.697520e+09</td>\n",
       "      <td>shallah</td>\n",
       "      <td>[Starvation due to climate change, There is le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Corn Could Grow in the Canadian Arctic Within ...</td>\n",
       "      <td></td>\n",
       "      <td>2371</td>\n",
       "      <td>17caxnf</td>\n",
       "      <td>climatechange</td>\n",
       "      <td>https://cleanenergyrevolution.co/2023/10/20/co...</td>\n",
       "      <td>448</td>\n",
       "      <td>1.697807e+09</td>\n",
       "      <td>Fickle-Flamingo1922</td>\n",
       "      <td>[“We’ll be growing oranges in Alaska”\\n\\n“God ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scientists say climate extremes of 2023 point ...</td>\n",
       "      <td></td>\n",
       "      <td>2274</td>\n",
       "      <td>17jzvwf</td>\n",
       "      <td>climatechange</td>\n",
       "      <td>https://www.newsweek.com/scientists-say-climat...</td>\n",
       "      <td>537</td>\n",
       "      <td>1.698690e+09</td>\n",
       "      <td>Splenda</td>\n",
       "      <td>[\"Hey guys, just in case you missed the last 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title body  score       id  \\\n",
       "0  Billions of crabs went missing around Alaska. ...        4428  17byrco   \n",
       "1  $266 Trillion in Climate Spending Is a No-Brai...        4144  17v43h4   \n",
       "2  Gray whales have been mysteriously washing up ...        2443  179qtvw   \n",
       "3  Corn Could Grow in the Canadian Arctic Within ...        2371  17caxnf   \n",
       "4  Scientists say climate extremes of 2023 point ...        2274  17jzvwf   \n",
       "\n",
       "       subreddit                                                url  \\\n",
       "0  climatechange  https://www.yahoo.com/news/billions-crabs-went...   \n",
       "1  climatechange  https://www.bloomberg.com/opinion/articles/202...   \n",
       "2  climatechange  https://www.businessinsider.nl/gray-whales-hav...   \n",
       "3  climatechange  https://cleanenergyrevolution.co/2023/10/20/co...   \n",
       "4  climatechange  https://www.newsweek.com/scientists-say-climat...   \n",
       "\n",
       "   num_comments       created               author  \\\n",
       "0           738  1.697764e+09                 None   \n",
       "1           677  1.699974e+09              Splenda   \n",
       "2           371  1.697520e+09              shallah   \n",
       "3           448  1.697807e+09  Fickle-Flamingo1922   \n",
       "4           537  1.698690e+09              Splenda   \n",
       "\n",
       "                                            comments  \n",
       "0  [So basically the deep ocean water got warm en...  \n",
       "1  [Back to Math \\n\\nThe earth has 7 billion huma...  \n",
       "2  [Starvation due to climate change, There is le...  \n",
       "3  [“We’ll be growing oranges in Alaska”\\n\\n“God ...  \n",
       "4  [\"Hey guys, just in case you missed the last 1...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch posts from a subreddit\n",
    "subreddit = reddit.subreddit('climatechange')  # Replace with your target subreddit; I chose climate change, you could literall chose anything from gaming to latest gadget out in the market\n",
    "\n",
    "posts = subreddit.top(limit=1000)  # Adjust the limit as needed\n",
    "\n",
    "data = []\n",
    "for post in posts:\n",
    "    post.comments.replace_more(limit=0)  # Fetch all comments\n",
    "    comments = []\n",
    "    for comment in post.comments.list():\n",
    "        comments.append(comment.body)\n",
    "    data.append([post.title, post.selftext, post.score, post.id, post.subreddit, post.url, post.num_comments, post.created_utc, post.author, comments])\n",
    "\n",
    "# Save to DataFrame\n",
    "df = pd.DataFrame(data, columns=['title', 'body', 'score', 'id', 'subreddit', 'url', 'num_comments', 'created', 'author', 'comments'])\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de6bbdd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc1b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('reddit_posts.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
